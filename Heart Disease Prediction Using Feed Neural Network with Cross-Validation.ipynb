{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d4b4be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras \n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras import regularizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from keras.callbacks import EarlyStopping, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d57c44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>318</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
       "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
       "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
       "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
       "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
       "5   58    0   0       100   248    0        0      122      0      1.0      1   \n",
       "6   58    1   0       114   318    0        2      140      0      4.4      0   \n",
       "7   55    1   0       160   289    0        0      145      1      0.8      1   \n",
       "8   46    1   0       120   249    0        0      144      0      0.8      2   \n",
       "9   54    1   0       122   286    0        0      116      1      3.2      1   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   2     3       0  \n",
       "1   0     3       0  \n",
       "2   0     3       0  \n",
       "3   1     3       0  \n",
       "4   3     2       0  \n",
       "5   0     2       1  \n",
       "6   3     1       0  \n",
       "7   1     3       0  \n",
       "8   0     3       0  \n",
       "9   2     2       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = r\"C:\\Users\\User\\Downloads\\archive\\heart.csv\"\n",
    "heart_disease = pd.read_csv(filepath)\n",
    "heart_disease.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97739ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease_features = heart_disease.drop('target',axis=1)\n",
    "heart_disease_label = heart_disease['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e3f94e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_features = heart_disease_features.to_numpy()\n",
    "numpy_label = heart_disease_label.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c11e938",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_label = numpy_label.reshape(1025,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f2aeeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of features: (1025, 13)\n",
      "The shape of label: (1025, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"The shape of features: {numpy_features.shape}\")\n",
    "print(f\"The shape of label: {numpy_label.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69ae66cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnn_model = keras.Sequential([\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2e35bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardizer=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b4d3164",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = []\n",
    "training_acc = []\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "precision_list = []\n",
    "recall_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9ec5621",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(learning_rate=0.001)\n",
    "bce = keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "accuracy = keras.metrics.BinaryAccuracy()\n",
    "recall = keras.metrics.Recall()\n",
    "precision = keras.metrics.Precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b72f304",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_log_path = r\"C:\\Users\\User\\Downloads\\heart_log\"\n",
    "log_path = os.path.join(base_log_path, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "es = EarlyStopping(monitor='val_loss',patience=5)\n",
    "tb = TensorBoard(log_dir=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75e67b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "kFold = KFold(n_splits=5, shuffle=True, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fa9818f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################################################\n",
      "Training for fold number 1\n",
      "Epoch 1/20\n",
      "26/26 [==============================] - 7s 77ms/step - loss: 0.6199 - binary_accuracy: 0.6634 - precision: 0.6548 - recall: 0.7639 - val_loss: 0.5092 - val_binary_accuracy: 0.8000 - val_precision: 0.7265 - val_recall: 0.9043\n",
      "Epoch 2/20\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.4861 - binary_accuracy: 0.7902 - precision: 0.7675 - recall: 0.8634 - val_loss: 0.3820 - val_binary_accuracy: 0.8439 - val_precision: 0.7925 - val_recall: 0.8936\n",
      "Epoch 3/20\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.4274 - binary_accuracy: 0.8171 - precision: 0.8079 - recall: 0.8565 - val_loss: 0.3470 - val_binary_accuracy: 0.8390 - val_precision: 0.7748 - val_recall: 0.9149\n",
      "Epoch 4/20\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.3798 - binary_accuracy: 0.8451 - precision: 0.8238 - recall: 0.8981 - val_loss: 0.3333 - val_binary_accuracy: 0.8537 - val_precision: 0.7963 - val_recall: 0.9149\n",
      "Epoch 5/20\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.3717 - binary_accuracy: 0.8463 - precision: 0.8228 - recall: 0.9028 - val_loss: 0.3218 - val_binary_accuracy: 0.8585 - val_precision: 0.8037 - val_recall: 0.9149\n",
      "Epoch 6/20\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.3410 - binary_accuracy: 0.8683 - precision: 0.8600 - recall: 0.8958 - val_loss: 0.3094 - val_binary_accuracy: 0.8585 - val_precision: 0.8095 - val_recall: 0.9043\n",
      "Epoch 7/20\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.3214 - binary_accuracy: 0.8720 - precision: 0.8674 - recall: 0.8935 - val_loss: 0.2946 - val_binary_accuracy: 0.8780 - val_precision: 0.8416 - val_recall: 0.9043\n",
      "Epoch 8/20\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.3244 - binary_accuracy: 0.8720 - precision: 0.8562 - recall: 0.9097 - val_loss: 0.2876 - val_binary_accuracy: 0.8878 - val_precision: 0.8447 - val_recall: 0.9255\n",
      "Epoch 9/20\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.2913 - binary_accuracy: 0.8878 - precision: 0.8744 - recall: 0.9190 - val_loss: 0.2806 - val_binary_accuracy: 0.8927 - val_precision: 0.8462 - val_recall: 0.9362\n",
      "Epoch 10/20\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.2893 - binary_accuracy: 0.8854 - precision: 0.8674 - recall: 0.9236 - val_loss: 0.2719 - val_binary_accuracy: 0.8976 - val_precision: 0.8614 - val_recall: 0.9255\n",
      "Epoch 11/20\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.2889 - binary_accuracy: 0.8902 - precision: 0.8851 - recall: 0.9097 - val_loss: 0.2625 - val_binary_accuracy: 0.8927 - val_precision: 0.8462 - val_recall: 0.9362\n",
      "Epoch 12/20\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.2757 - binary_accuracy: 0.8902 - precision: 0.8886 - recall: 0.9051 - val_loss: 0.2485 - val_binary_accuracy: 0.8976 - val_precision: 0.8614 - val_recall: 0.9255\n",
      "Epoch 13/20\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.2615 - binary_accuracy: 0.9012 - precision: 0.8891 - recall: 0.9282 - val_loss: 0.2397 - val_binary_accuracy: 0.9024 - val_precision: 0.8627 - val_recall: 0.9362\n",
      "Epoch 14/20\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.2603 - binary_accuracy: 0.9037 - precision: 0.9039 - recall: 0.9144 - val_loss: 0.2342 - val_binary_accuracy: 0.9073 - val_precision: 0.8641 - val_recall: 0.9468\n",
      "Epoch 15/20\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.2296 - binary_accuracy: 0.9134 - precision: 0.9020 - recall: 0.9375 - val_loss: 0.2291 - val_binary_accuracy: 0.9171 - val_precision: 0.8889 - val_recall: 0.9362\n",
      "Epoch 16/20\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.2246 - binary_accuracy: 0.9146 - precision: 0.9058 - recall: 0.9352 - val_loss: 0.2253 - val_binary_accuracy: 0.9073 - val_precision: 0.8713 - val_recall: 0.9362\n",
      "Epoch 17/20\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.2255 - binary_accuracy: 0.9037 - precision: 0.9021 - recall: 0.9167 - val_loss: 0.2396 - val_binary_accuracy: 0.8976 - val_precision: 0.8614 - val_recall: 0.9255\n",
      "Epoch 18/20\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.2123 - binary_accuracy: 0.9244 - precision: 0.9129 - recall: 0.9468 - val_loss: 0.2218 - val_binary_accuracy: 0.9220 - val_precision: 0.8980 - val_recall: 0.9362\n",
      "Epoch 19/20\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.1847 - binary_accuracy: 0.9256 - precision: 0.9187 - recall: 0.9421 - val_loss: 0.2110 - val_binary_accuracy: 0.9268 - val_precision: 0.8911 - val_recall: 0.9574\n",
      "Epoch 20/20\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.1819 - binary_accuracy: 0.9341 - precision: 0.9276 - recall: 0.9491 - val_loss: 0.2237 - val_binary_accuracy: 0.9268 - val_precision: 0.8911 - val_recall: 0.9574\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2237 - binary_accuracy: 0.9268 - precision: 0.8911 - recall: 0.9574\n",
      "Score for fold 1: \n",
      "loss : 0.22368201613426208\n",
      "\n",
      "binary_accuracy : 0.9268292784690857\n",
      "\n",
      "precision : 0.8910890817642212\n",
      "\n",
      "recall : 0.957446813583374\n",
      "\n",
      "########################################################################\n",
      "Training for fold number 2\n",
      "Epoch 1/20\n",
      "26/26 [==============================] - 3s 68ms/step - loss: 0.2079 - binary_accuracy: 0.9171 - precision: 0.9017 - recall: 0.9382 - val_loss: 0.1366 - val_binary_accuracy: 0.9561 - val_precision: 0.9429 - val_recall: 0.9706\n",
      "Epoch 2/20\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.1771 - binary_accuracy: 0.9268 - precision: 0.9155 - recall: 0.9458 - val_loss: 0.1376 - val_binary_accuracy: 0.9415 - val_precision: 0.9500 - val_recall: 0.9314\n",
      "Epoch 3/20\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.1654 - binary_accuracy: 0.9378 - precision: 0.9268 - recall: 0.9552 - val_loss: 0.1363 - val_binary_accuracy: 0.9415 - val_precision: 0.9327 - val_recall: 0.9510\n",
      "Epoch 4/20\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.1821 - binary_accuracy: 0.9317 - precision: 0.9259 - recall: 0.9434 - val_loss: 0.1357 - val_binary_accuracy: 0.9366 - val_precision: 0.9406 - val_recall: 0.9314\n",
      "Epoch 5/20\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.1647 - binary_accuracy: 0.9293 - precision: 0.9197 - recall: 0.9458 - val_loss: 0.1244 - val_binary_accuracy: 0.9512 - val_precision: 0.9510 - val_recall: 0.9510\n",
      "Epoch 6/20\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.1501 - binary_accuracy: 0.9451 - precision: 0.9523 - recall: 0.9410 - val_loss: 0.1115 - val_binary_accuracy: 0.9610 - val_precision: 0.9700 - val_recall: 0.9510\n",
      "Epoch 7/20\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.1354 - binary_accuracy: 0.9500 - precision: 0.9506 - recall: 0.9528 - val_loss: 0.1043 - val_binary_accuracy: 0.9610 - val_precision: 0.9608 - val_recall: 0.9608\n",
      "Epoch 8/20\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.1383 - binary_accuracy: 0.9427 - precision: 0.9314 - recall: 0.9599 - val_loss: 0.1031 - val_binary_accuracy: 0.9659 - val_precision: 0.9703 - val_recall: 0.9608\n",
      "Epoch 9/20\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.1350 - binary_accuracy: 0.9451 - precision: 0.9501 - recall: 0.9434 - val_loss: 0.0957 - val_binary_accuracy: 0.9707 - val_precision: 0.9615 - val_recall: 0.9804\n",
      "Epoch 10/20\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.1182 - binary_accuracy: 0.9561 - precision: 0.9491 - recall: 0.9670 - val_loss: 0.0891 - val_binary_accuracy: 0.9659 - val_precision: 0.9703 - val_recall: 0.9608\n",
      "Epoch 11/20\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.1254 - binary_accuracy: 0.9512 - precision: 0.9507 - recall: 0.9552 - val_loss: 0.0865 - val_binary_accuracy: 0.9659 - val_precision: 0.9703 - val_recall: 0.9608\n",
      "Epoch 12/20\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.0990 - binary_accuracy: 0.9573 - precision: 0.9471 - recall: 0.9717 - val_loss: 0.0834 - val_binary_accuracy: 0.9659 - val_precision: 0.9703 - val_recall: 0.9608\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 24ms/step - loss: 0.1141 - binary_accuracy: 0.9622 - precision: 0.9667 - recall: 0.9599 - val_loss: 0.0846 - val_binary_accuracy: 0.9561 - val_precision: 0.9697 - val_recall: 0.9412\n",
      "Epoch 14/20\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.1167 - binary_accuracy: 0.9585 - precision: 0.9514 - recall: 0.9693 - val_loss: 0.0722 - val_binary_accuracy: 0.9659 - val_precision: 0.9703 - val_recall: 0.9608\n",
      "Epoch 15/20\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.1174 - binary_accuracy: 0.9585 - precision: 0.9514 - recall: 0.9693 - val_loss: 0.0893 - val_binary_accuracy: 0.9561 - val_precision: 0.9697 - val_recall: 0.9412\n",
      "Epoch 16/20\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.0976 - binary_accuracy: 0.9659 - precision: 0.9583 - recall: 0.9764 - val_loss: 0.0700 - val_binary_accuracy: 0.9659 - val_precision: 0.9703 - val_recall: 0.9608\n",
      "Epoch 17/20\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.0944 - binary_accuracy: 0.9768 - precision: 0.9698 - recall: 0.9858 - val_loss: 0.0690 - val_binary_accuracy: 0.9659 - val_precision: 0.9703 - val_recall: 0.9608\n",
      "Epoch 18/20\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.0939 - binary_accuracy: 0.9659 - precision: 0.9605 - recall: 0.9741 - val_loss: 0.0573 - val_binary_accuracy: 0.9756 - val_precision: 0.9899 - val_recall: 0.9608\n",
      "Epoch 19/20\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.0928 - binary_accuracy: 0.9695 - precision: 0.9716 - recall: 0.9693 - val_loss: 0.0560 - val_binary_accuracy: 0.9854 - val_precision: 0.9714 - val_recall: 1.0000\n",
      "Epoch 20/20\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.1028 - binary_accuracy: 0.9585 - precision: 0.9577 - recall: 0.9623 - val_loss: 0.0701 - val_binary_accuracy: 0.9707 - val_precision: 0.9898 - val_recall: 0.9510\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0701 - binary_accuracy: 0.9707 - precision: 0.9898 - recall: 0.9510\n",
      "Score for fold 2: \n",
      "loss : 0.07010107487440109\n",
      "\n",
      "binary_accuracy : 0.9707317352294922\n",
      "\n",
      "precision : 0.9897959232330322\n",
      "\n",
      "recall : 0.9509803652763367\n",
      "\n",
      "########################################################################\n",
      "Training for fold number 3\n",
      "Epoch 1/20\n",
      "26/26 [==============================] - 3s 71ms/step - loss: 0.0952 - binary_accuracy: 0.9659 - precision: 0.9762 - recall: 0.9554 - val_loss: 0.0286 - val_binary_accuracy: 0.9951 - val_precision: 0.9912 - val_recall: 1.0000\n",
      "Epoch 2/20\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.1012 - binary_accuracy: 0.9646 - precision: 0.9616 - recall: 0.9686 - val_loss: 0.0312 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 3/20\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.0976 - binary_accuracy: 0.9671 - precision: 0.9663 - recall: 0.9686 - val_loss: 0.0346 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 4/20\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0788 - binary_accuracy: 0.9744 - precision: 0.9712 - recall: 0.9783 - val_loss: 0.0263 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 5/20\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.0773 - binary_accuracy: 0.9720 - precision: 0.9734 - recall: 0.9710 - val_loss: 0.0237 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 6/20\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.0898 - binary_accuracy: 0.9695 - precision: 0.9687 - recall: 0.9710 - val_loss: 0.0228 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 7/20\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.0882 - binary_accuracy: 0.9744 - precision: 0.9735 - recall: 0.9758 - val_loss: 0.0204 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 8/20\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0598 - binary_accuracy: 0.9817 - precision: 0.9761 - recall: 0.9879 - val_loss: 0.0214 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 9/20\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0719 - binary_accuracy: 0.9707 - precision: 0.9643 - recall: 0.9783 - val_loss: 0.0246 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 10/20\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0813 - binary_accuracy: 0.9671 - precision: 0.9801 - recall: 0.9541 - val_loss: 0.0150 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 11/20\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0717 - binary_accuracy: 0.9829 - precision: 0.9785 - recall: 0.9879 - val_loss: 0.0226 - val_binary_accuracy: 0.9951 - val_precision: 1.0000 - val_recall: 0.9911\n",
      "Epoch 12/20\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.0478 - binary_accuracy: 0.9817 - precision: 0.9784 - recall: 0.9855 - val_loss: 0.0192 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 13/20\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.0724 - binary_accuracy: 0.9707 - precision: 0.9710 - recall: 0.9710 - val_loss: 0.0165 - val_binary_accuracy: 0.9951 - val_precision: 1.0000 - val_recall: 0.9911\n",
      "Epoch 14/20\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.0617 - binary_accuracy: 0.9793 - precision: 0.9830 - recall: 0.9758 - val_loss: 0.0167 - val_binary_accuracy: 0.9951 - val_precision: 1.0000 - val_recall: 0.9911\n",
      "Epoch 15/20\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.0482 - binary_accuracy: 0.9878 - precision: 0.9903 - recall: 0.9855 - val_loss: 0.0155 - val_binary_accuracy: 0.9951 - val_precision: 1.0000 - val_recall: 0.9911\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0155 - binary_accuracy: 0.9951 - precision: 1.0000 - recall: 0.9911\n",
      "Score for fold 3: \n",
      "loss : 0.015507202595472336\n",
      "\n",
      "binary_accuracy : 0.995121955871582\n",
      "\n",
      "precision : 1.0\n",
      "\n",
      "recall : 0.9910714030265808\n",
      "\n",
      "########################################################################\n",
      "Training for fold number 4\n",
      "Epoch 1/20\n",
      "26/26 [==============================] - 4s 77ms/step - loss: 0.0502 - binary_accuracy: 0.9883 - precision: 0.9887 - recall: 0.9887 - val_loss: 0.0126 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 2/20\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.0427 - binary_accuracy: 0.9890 - precision: 0.9880 - recall: 0.9904 - val_loss: 0.0123 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 3/20\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.0574 - binary_accuracy: 0.9841 - precision: 0.9810 - recall: 0.9880 - val_loss: 0.0139 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 4/20\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.0603 - binary_accuracy: 0.9805 - precision: 0.9808 - recall: 0.9808 - val_loss: 0.0136 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 5/20\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.0363 - binary_accuracy: 0.9866 - precision: 0.9833 - recall: 0.9904 - val_loss: 0.0142 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 6/20\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.0296 - binary_accuracy: 0.9915 - precision: 0.9881 - recall: 0.9952 - val_loss: 0.0115 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 7/20\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.0382 - binary_accuracy: 0.9890 - precision: 0.9904 - recall: 0.9880 - val_loss: 0.0116 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 8/20\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.0399 - binary_accuracy: 0.9890 - precision: 0.9880 - recall: 0.9904 - val_loss: 0.0128 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 25ms/step - loss: 0.0400 - binary_accuracy: 0.9890 - precision: 0.9928 - recall: 0.9856 - val_loss: 0.0090 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 10/20\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0361 - binary_accuracy: 0.9878 - precision: 0.9951 - recall: 0.9808 - val_loss: 0.0075 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 11/20\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.0313 - binary_accuracy: 0.9915 - precision: 0.9928 - recall: 0.9904 - val_loss: 0.0105 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 12/20\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.0459 - binary_accuracy: 0.9890 - precision: 0.9880 - recall: 0.9904 - val_loss: 0.0075 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 13/20\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0396 - binary_accuracy: 0.9854 - precision: 0.9810 - recall: 0.9904 - val_loss: 0.0088 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 14/20\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.0406 - binary_accuracy: 0.9854 - precision: 0.9856 - recall: 0.9856 - val_loss: 0.0079 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 15/20\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.0390 - binary_accuracy: 0.9854 - precision: 0.9880 - recall: 0.9832 - val_loss: 0.0071 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 16/20\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.0298 - binary_accuracy: 0.9915 - precision: 0.9928 - recall: 0.9904 - val_loss: 0.0070 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 17/20\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0454 - binary_accuracy: 0.9878 - precision: 0.9834 - recall: 0.9928 - val_loss: 0.0071 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 18/20\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.0308 - binary_accuracy: 0.9866 - precision: 0.9880 - recall: 0.9856 - val_loss: 0.0079 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 19/20\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.0427 - binary_accuracy: 0.9854 - precision: 0.9903 - recall: 0.9808 - val_loss: 0.0079 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 20/20\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.0431 - binary_accuracy: 0.9841 - precision: 0.9856 - recall: 0.9832 - val_loss: 0.0099 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0099 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Score for fold 4: \n",
      "loss : 0.009868682362139225\n",
      "\n",
      "binary_accuracy : 1.0\n",
      "\n",
      "precision : 1.0\n",
      "\n",
      "recall : 1.0\n",
      "\n",
      "########################################################################\n",
      "Training for fold number 5\n",
      "Epoch 1/20\n",
      "26/26 [==============================] - 3s 67ms/step - loss: 0.0375 - binary_accuracy: 0.9902 - precision: 0.9868 - recall: 0.9943 - val_loss: 0.0078 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 2/20\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.0321 - binary_accuracy: 0.9915 - precision: 0.9904 - recall: 0.9928 - val_loss: 0.0081 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 3/20\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.0353 - binary_accuracy: 0.9902 - precision: 0.9881 - recall: 0.9928 - val_loss: 0.0088 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 4/20\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0402 - binary_accuracy: 0.9854 - precision: 0.9880 - recall: 0.9832 - val_loss: 0.0094 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 5/20\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.0349 - binary_accuracy: 0.9890 - precision: 0.9880 - recall: 0.9904 - val_loss: 0.0072 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 6/20\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.0261 - binary_accuracy: 0.9963 - precision: 0.9976 - recall: 0.9952 - val_loss: 0.0054 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 7/20\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0275 - binary_accuracy: 0.9939 - precision: 0.9928 - recall: 0.9952 - val_loss: 0.0070 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 8/20\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.0297 - binary_accuracy: 0.9890 - precision: 0.9857 - recall: 0.9928 - val_loss: 0.0069 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 9/20\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.0453 - binary_accuracy: 0.9878 - precision: 0.9880 - recall: 0.9880 - val_loss: 0.0049 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 10/20\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.0397 - binary_accuracy: 0.9854 - precision: 0.9880 - recall: 0.9832 - val_loss: 0.0055 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 11/20\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.0389 - binary_accuracy: 0.9854 - precision: 0.9810 - recall: 0.9904 - val_loss: 0.0054 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 12/20\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.0304 - binary_accuracy: 0.9902 - precision: 0.9928 - recall: 0.9880 - val_loss: 0.0057 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 13/20\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.0349 - binary_accuracy: 0.9927 - precision: 0.9976 - recall: 0.9880 - val_loss: 0.0055 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 14/20\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.0210 - binary_accuracy: 0.9927 - precision: 0.9928 - recall: 0.9928 - val_loss: 0.0041 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 15/20\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.0296 - binary_accuracy: 0.9915 - precision: 0.9928 - recall: 0.9904 - val_loss: 0.0056 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 16/20\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.0167 - binary_accuracy: 0.9951 - precision: 0.9928 - recall: 0.9976 - val_loss: 0.0063 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 17/20\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.0324 - binary_accuracy: 0.9878 - precision: 0.9904 - recall: 0.9856 - val_loss: 0.0054 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 18/20\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.0279 - binary_accuracy: 0.9927 - precision: 0.9905 - recall: 0.9952 - val_loss: 0.0043 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 19/20\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.0400 - binary_accuracy: 0.9915 - precision: 0.9928 - recall: 0.9904 - val_loss: 0.0049 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0049 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Score for fold 5: \n",
      "loss : 0.0049045695923268795\n",
      "\n",
      "binary_accuracy : 1.0\n",
      "\n",
      "precision : 1.0\n",
      "\n",
      "recall : 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fold_no = 1\n",
    "for train, test in kFold.split(numpy_features, numpy_label):\n",
    "    numpy_features[train] = standardizer.fit_transform(numpy_features[train])  #do data normalization to remove outliers, biases etc.\n",
    "    numpy_features[test] = standardizer.transform(numpy_features[test])\n",
    "    fnn_model.compile(optimizer=adam, loss=bce, \n",
    "                  metrics=[accuracy, precision, recall])\n",
    "    print('########################################################################')\n",
    "    print(f'Training for fold number {fold_no}')\n",
    "    history = fnn_model.fit(numpy_features[train], numpy_label[train],\n",
    "                        validation_data=(numpy_features[test], numpy_label[test]),\n",
    "                        batch_size=32, epochs=20, callbacks=[es,tb])\n",
    "    training_loss.append(history.history['loss'])\n",
    "    training_acc.append(history.history['binary_accuracy'])\n",
    "    val_loss.append(history.history['val_loss'])\n",
    "    val_acc.append(history.history['val_binary_accuracy'])\n",
    "    scores = fnn_model.evaluate(numpy_features[test], numpy_label[test])\n",
    "    print(f'Score for fold {fold_no}: ')\n",
    "    loss_list.append(scores[0])\n",
    "    acc_list.append(scores[1])\n",
    "    precision_list.append(scores[2])\n",
    "    recall_list.append(scores[3])\n",
    "    for metric_name, score in zip(fnn_model.metrics_names, scores):\n",
    "        print(f'{metric_name} : {score}')\n",
    "        print()\n",
    "    fold_no += 1\n",
    "    keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "682d1554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss : 0.06481270911172032\n",
      "Average Accuracy : 0.978536593914032\n",
      "Average Precision : 0.9761770009994507\n",
      "Average Recall : 0.9798997163772583\n"
     ]
    }
   ],
   "source": [
    "print('Average Loss :',np.mean(loss_list))\n",
    "print('Average Accuracy :', np.mean(acc_list))\n",
    "print('Average Precision :', np.mean(precision_list))\n",
    "print('Average Recall :', np.mean(recall_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
